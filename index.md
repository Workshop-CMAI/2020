Artificial intelligence (AI) is front and center in the data-driven revolution that has been taking place in the last couple of years with the increasing availability of large amounts of data (“big data”) in virtually every domain. The now dominant paradigm of data-driven AI, powered by sophisticated machine learning algorithms, employs big data to build intelligent applications and support fact-based decision making. The focus of data-driven AI is on learning (domain) models and keeping those models up-to-date by using statistical methods over big data, in contrast to the manual modeling approach prevalent in traditional, knowledge-based AI.

While data-driven AI has led to significant breakthroughs, it also comes with a number of disadvantages. First, models generated by machine learning algorithms often cannot be inspected and understood by a human being, thus lacking explainability. Furthermore, integration of preexisting domain knowledge into learned models -- prior to or after learning -- is difficult. Finally, correct application of data-driven AI depends on the domain, problem, and organizational context while considering human aspects as well. Conceptual modeling can be the key to applying data-driven AI in a meaningful, correct, and time-efficient way while improving maintainability, usability, and explainability. In particular, we expect contributions in the following key areas:

**1. Augmenting Data-Driven AI with Conceptual Modeling for Explainable AI**

Data-driven AI generates models that may be either symbolic (e.g. rules, decision trees) or sub-symbolic (neural networks). These models will then be used in application systems to implement specific functions and/or behavior, e.g., object detection in images, scene understanding in videos, medical diagnoses, interpreting sensor data. Typically, these models cannot be inspected and understood by a human being. Models of a symbolic nature tend to be too complex, whereas sub-symbolic models do not contain structural elements that can be understood by humans. In many application scenarios, however, this is an important requirement. Various approaches to explainability, model testing and verification are based on integrating data-driven AI with approaches from conceptual modeling.

**2. Supporting Data-Driven Decision Making with Conceptual Modeling**

Business intelligence (BI) and analytics projects require domain experts, business people, data scientists, and engineers to communicate with each other in a common language. Stakeholders must collaborate in various ways in order to gain a common understanding of the problem as well as to decide on the appropriate data model, architecture, algorithms, user interfaces, etc. Yet, BI and analytics projects often involve low-level, ad hoc data wrangling and programming, which increases development effort and reduces usability of BI and analytics solutions. Furthermore, data analytics and machine learning techniques are often misapplied, adversely affecting the validity of analysis results in practice. A conceptual perspective on data-driven decision making ensures that analysts employ algorithms in the correct context and use the appropriate systems to process the available data in a meaningful way. Conceptual modeling allows to move data-driven decision making onto a higher level of abstraction, facilitating implementation and use of data analytics solutions while allowing stakeholders with different skills to communicate with each other.

**3. Using Data-Driven Model Generation for Conceptual Modeling**

Conceptual modeling is not necessarily a (purely) manual undertaking but can benefit from approaches to model generation. For example, a first draft of a conceptual model might be generated from existing data which will then be extended and refined manually. Furthermore, individual parts of a conceptual model may be generated automatically whereas other parts are handcrafted. Existing models might be (semi-)automatically improved based on regularities derived from newly available data, which may form the basis for self-tuning and self-repairing systems.

Topics of Interest
----
- Combining generated and manually engineered models
- Combining symbolic with sub-symbolic models
- Conceptual (meta-)models as background knowledge for model learning
- Explainability of learned models
- Conceptual models for enabling explainability, model validation and plausibility checking
- Trade-off between explainability and model performance
- Trade-off between comprehensibility of an explanation and its completeness
- Reasoning in generated models
- Data-driven modeling support
- Learning of meta-models
- Automatic, incremental model adaptation
- Model-driven guidance and support for data analytics lifecycle
- Conceptual models for supporting users with conducting data analysis

Important Dates
----
Paper Submissions: 6th July 2020

Author Notifications: 27th July 2020

Camera-Ready Paper Submissions: 11th August 2020 

Paper Submission
----

Workshop Organizers
----

- Dominik Bork, University of Vienna, Austria
- Peter Fettke, German Research Center for Artificial Intelligence, Germany
- Wolfgang Maass, German Research Center for Artificial Intelligence, Germany
- Ulrich Reimer, University of Applied Sciences St. Gallen, Switzerland
- Christoph G. Schuetz, Johannes Kepler University Linz, Austria
- Marina Tropmann-Frick, University of Applied Sciences Hamburg, Germany
- Eric S. K. Yu, University of Toronto, Canada

Program Committee
----
- Loris Bozzato, Fondazione Bruno Kessler, Italy
- Aditya Ghose, University of Wollongong, Australia
- Josef Küng, Johannes Kepler University Linz, Austria
- Bernd Neumayr, Johannes Kepler University Linz, Austria
- Oscar Romero, Universitat Politècnica de Catalunya, Spain
- Michael Schrefl, Johannes Kepler University Linz, Austria
- Matt Selway, University of South Australia, Adelaide
- Luciano Serafini, Fondazione Bruno Kessler, Italy
- Stefan Thalmann, University of Graz, Austria

*To be finalized*


